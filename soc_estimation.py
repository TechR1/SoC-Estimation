# -*- coding: utf-8 -*-
"""SoC Estimation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1q1h53_OJ9qJHGCthvG2C6jymh3BuNc_e

# Estimating SoC of Batteries : A DL approach

## Context
- State-of-charge is a crucial parameter of a Battery, defined as the ratio of available capacity to maximum capacity, which cannot be measured but only inferred.
- In a EV, SoC is analogous to a Fuel gauge of a combustion vehicle, hence need to be estimated with a high accuracy.
- SoC of a Lithium-ion battery is a non-linear complex function of voltage, current, temperature and health of battery, which is not completely understood yet.
- This is an attempt to take a non-conventional data-based approach to tackle the problem of estimating SoC.
***
## Specifics of Training Data
- The battery taken here is LG HG2 18650, whose datasheet can be found [here](https://www.batteryspace.com/prod-specs/9989.specs.pdf).
- The battery is subject to various tests and the battery parameters are measured, which are then processed to form training data.
- The dataset upon which model is trained is taken from : https://data.mendeley.com/datasets/cp3473x7xv/3 
***
## Approach
- Planning to build feed forward neural network to predict the SoC values.

## Import necessary libs
"""

!pip install mat4py

# Commented out IPython magic to ensure Python compatibility.
import torch
import torchvision
import torch.nn as nn
import mat4py
from torch.utils.data import TensorDataset, DataLoader
from torchvision.datasets.utils import download_url
import os
import pandas as pd
from zipfile import ZipFile
import matplotlib.pyplot as plt
# %matplotlib inline
#import antigravity

"""## Jovian Commits"""

#import jovian

#Project name used for jovian.commit
#project_name = 'soc-estimation'

#jovian.commit(project=project_name, environment=None)

"""## Helper Functions"""

def fixBadZipfile(zipFile):
  f = open(zipFile, 'r+b')
  data = f.read()
  pos = data.find('\x50\x4b\x05\x06') 
  if (pos>0):
    self._log("Truncating file at location" + str(pos + 22) + ".")
    f.seek(pos + 22)
    f.truncate()
    f.close()


def zipExtracter(file_name):
    
    with ZipFile(file_name, 'r') as zip:
        zip.printdir()
        print('Extracting all files now...')
        zip.extractall()
        print('Done!')
        
def matfile_to_tensor(path):
    #Load the mat file as a dictionary
    data = mat4py.loadmat(path)
    
    #Convert the inputs from list to tensor
    train_inputs = pd.DataFrame(data['X'])
    inputs = train_inputs.to_numpy()
    
    #Take a transpose since the input data here is given column-wise
    inputs = inputs.transpose()
    inputs = torch.from_numpy(inputs).to(torch.float32)
   
    #Convert the target from list to tensor
    train_targets = pd.DataFrame(data['Y'])
    targets = train_targets.to_numpy()
    targets = torch.from_numpy(targets).to(torch.float32)
    
    return inputs, targets

"""## Load Dataset"""

from google.colab import drive
drive.mount('/content/drive')

DATASET_URL = 'https://data.mendeley.com/public-files/datasets/cp3473x7xv/files/ad7ac5c9-2b9e-458a-a91f-6f3da449bdfb/file_downloaded'
path = '/content/drive/MyDrive/RFR - STAGING AREA/SoC NN'
DATA_FILENAME = 'LGHG2.zip'
download_url(DATASET_URL, path, DATA_FILENAME)
#fixBadZipfile(path)
zipExtracter(path+'/'+DATA_FILENAME)

TRAIN_FILE_PATH = './Train/'+os.listdir('./Train')[0]
VAL_FILE_PATH = './Validation/' + os.listdir('./Validation')[0]
train_ds = TensorDataset(*matfile_to_tensor(TRAIN_FILE_PATH))
val_ds = TensorDataset(*matfile_to_tensor(VAL_FILE_PATH))
len(train_ds) , len(val_ds)

batch_size = 4096
train_size = 0.1*len(train_ds)
val_size = 0.1*len(val_ds)
train_dl = DataLoader(train_ds, batch_size, shuffle=False)
val_dl = DataLoader(val_ds, batch_size, shuffle = False)

for xb, yb in train_dl :
    print("Inputs", xb)
    #print("Outputs", yb)
    break

"""## Define the Model"""

in_size = 5
hidden_1 = 55
hidden_2 = 55
out_size = 1
loss_fn = nn.MSELoss()

class soc_Estimator(nn.Module):
    
    def __init__(self, in_size, hidden_1, hidden_2, out_size):
        super().__init__()
        self.network = nn.Sequential(
            nn.Linear(in_size, hidden_1),
            nn.Tanh(),
            nn.Linear(hidden_1, hidden_2),
            nn.LeakyReLU(0.3),
            nn.Linear(hidden_2, out_size)
        )
        
    def forward(self, xb):
        out = self.network(xb)
        out = torch.clamp(out,min=0, max=1)
        return out
    
    def training_step(self, batch):
        inputs, targets = batch
        #Generate pred.
        out = self(inputs)
        #Calculate loss
        loss = loss_fn(out, targets)
        return loss
    
    def validation_step(self, batch):
        inputs, targets = batch
        out = self(inputs)
        loss = loss_fn(out, targets)
        return {'val_loss': loss.detach()}
    
    def validation_epoch_end(self, outputs):
        batch_losses = [x['val_loss'] for x in outputs]
        epoch_loss = torch.stack(batch_losses).mean() # Combine losses
        return {'val_loss': epoch_loss.item()}
    
    def epoch_end(self, epoch, result):
        print("Epoch [{}], Train_loss: {:.4f}, Val_loss: {:.4f}".format(epoch+1, result['train_loss'], result['val_loss']))

model = soc_Estimator(in_size, hidden_1, hidden_2, out_size)
list(model.parameters())

"""## Use GPU"""

def get_default_device():
    '''Pick a GPU if available, else CPU'''
    if torch.cuda.is_available():
        return torch.device('cuda')
    else:
        return torch.device('cpu')
    
def to_device(data, device):
    '''Move tensors to chosen device'''
    if isinstance(data, (list, tuple)):
        return [to_device(x, device) for x in data]
    
    return data.to(device, non_blocking=True)

class DeviceDataLoader():
    '''Wrap a dataloader t move data to device'''
    def __init__(self, dl, device):
        self.dl = dl
        self.device = device
        
    def __iter__(self):
        for b in self.dl:
            yield to_device(b, self.device)
            
    def __len__(self):
        return len(self.dl)

device = get_default_device()

train_dl = DeviceDataLoader(train_dl, device)
val_dl = DeviceDataLoader(train_dl, device)

model = to_device(model, device)

"""## Train the model"""

@torch.no_grad()
def evaluate(model, val_loader):
    model.eval()
    outputs = [model.validation_step(batch) for batch in val_loader]
    return model.validation_epoch_end(outputs)

def get_lr(optimizer):
    for param_group in optimizer.param_groups:
        return param_group['lr']
    
def fit(epochs, max_lr, model, train_loader, val_loader, 
                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):
    torch.cuda.empty_cache()
    history = []
    
    optimizer = opt_func(model.parameters(), max_lr)
    #sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, steps_pr_epoch=len(train_loader))
    
    for epoch in range(epochs):
        model.train()
        train_losses = []
        lrs = []
        for batch in train_loader:
            loss = model.training_step(batch)
            train_losses.append(loss)
            loss.backward()
            
            if grad_clip:
                nn.utils.clip_grad_value_(model.parameters(), grad_clip)
                
            optimizer.step()
            optimizer.zero_grad()
            
            #lrs.append(get_lr(optimizer))
            #sched.step()
            
        result = evaluate(model, val_loader)
        result['train_loss'] = torch.stack(train_losses).mean().item()
        model.epoch_end(epoch, result)
        history.append(result)
    return history

# Commented out IPython magic to ensure Python compatibility.
# %%time
# history = [evaluate(model, val_dl)]
# print(history)

epochs = 50
max_lr = 0.01
grad_clip = 1
weight_decay = 0
opt_func = torch.optim.SGD

# Commented out IPython magic to ensure Python compatibility.
# %%time
# history0 = []
# history0 += fit(epochs, max_lr, model, train_dl, val_dl,weight_decay,grad_clip, opt_func)

"""## Visualize Results"""

def plot_train_loss(history):
  losses = [x['train_loss'] for x in history]
  plt.plot(losses, '-x')
  plt.xlabel('epoch')
  plt.ylabel('Train losses')
  plt.title('Train loss vs No. of epochs')

def plot_val_loss(history):
  losses = [x['val_loss'] for x in history]
  plt.plot(losses, '-x')
  plt.xlabel('epoch')
  plt.ylabel('Val losses')
  plt.title('Val loss vs No. of epochs')

plot_train_loss(history0)

plot_val_loss(history0)

def predict_single(input, target, model):
  inputs = input.unsqueeze(0)
  predictions = model(inputs)
  prediction = prediction[0].detach()
  print("Input : ", input)
  print("Target : ", target)
  print("prediction : ", prediction)